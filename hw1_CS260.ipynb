{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1_CS260.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6Ao4y5lICs-"
      },
      "source": [
        "#HOMEWORK #1 CS 260\n",
        "#AMIR DHILLON \n",
        "#January 25 2021\n",
        "#UID : 005-649-833\n",
        "# References :\n",
        "#https://github.com/AnupamMicrosoft/PyTorch-Classification/blob/master/README.md\n",
        "#https://pytorch.org/get-started/locally/\n",
        "#https://stackoverflow.com/questions/61599465/why-does-by-torch-optim-sgd-method-learning-rate-change\n",
        "#https://stackoverflow.com/questions/48324152/pytorch-how-to-change-the-learning-rate-of-an-optimizer-at-any-given-moment-no/48324389"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yznuOWLp6tcR"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.nn import functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OammkTrV7Gka"
      },
      "source": [
        "#Hyper-parameters \n",
        "\n",
        "batch_size = 64 #this is not changed\n",
        "num_epochs = 10  # number of times you will iterate through the full training data\n",
        "learning_rate = 0.0001 ## step size used by SGD \n",
        "momentum = 0.9 ## Momentum is a moving average of our gradients (helps to keep direction)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_Ui8A5e7PPM"
      },
      "source": [
        "## USE THIS SNIPPET TO GET BINARY TRAIN/TEST DATA\n",
        "\n",
        "train_data = datasets.MNIST('./data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "test_data = datasets.MNIST('./data', train=False, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "\n",
        "subset_indices = ((train_data.targets == 0) + (train_data.targets == 1)).nonzero()\n",
        "train_loader = torch.utils.data.DataLoader(train_data,batch_size=batch_size, \n",
        "  shuffle=False,sampler=SubsetRandomSampler(subset_indices.view(-1)))\n",
        "\n",
        "\n",
        "subset_indices = ((test_data.targets == 0) + (test_data.targets == 1)).nonzero()\n",
        "test_loader = torch.utils.data.DataLoader(test_data,batch_size=batch_size, \n",
        "  shuffle=False,sampler=SubsetRandomSampler(subset_indices.view(-1)))\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLZssifE7p6V"
      },
      "source": [
        "#(image size, number of classes)\n",
        "#Logistic regression model and Loss\n",
        "\n",
        "Logistics_model = nn.Linear(28*28,1)\n",
        "Logistics_momentum = nn.Linear(28*28,1)\n",
        "\n",
        "#Logistic Regression Optimizer\n",
        "\n",
        "optimizer_logistics_reg = torch.optim.SGD(Logistics_model.parameters(), lr=learning_rate)\n",
        "optimizer_logistics_momentum = torch.optim.SGD(Logistics_momentum.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "#SVM/regression  \n",
        "#(image size, number of classes)\n",
        "SVM_model = nn.Linear(28*28,1)\n",
        "SVM_Momentum = nn.Linear(28*28,1)\n",
        "\n",
        "\n",
        "optimizer_SGD= torch.optim.SGD(SVM_model.parameters(),lr=learning_rate)\n",
        "optimizer_Momentum= torch.optim.SGD(SVM_Momentum.parameters(),lr=lrate,momentum=momentum)\n",
        "\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY_bIvXyZTHH",
        "outputId": "dcdbc697-2afa-4402-a175-bae3ddac6d53"
      },
      "source": [
        "# Training the Model\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    total_batches=0\n",
        "    \n",
        "    total_loss_momentum=0\n",
        "    total_loss_logression=0\n",
        "    total_loss_logression_momentum=0\n",
        "    \n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.view(-1, 28*28)\n",
        "        #Convert labels from 0,1 to -1,1\n",
        "        labels = 2*(labels.float()-0.5)\n",
        "        label_momentum = 2*(labels.float()-0.5)\n",
        "        \n",
        "        ## TODO \n",
        "        output = SVM_model(images)\n",
        "        output_momentum = SVM_Momentum(images)\n",
        "        output_logression=Logistics_model(images)\n",
        "        output_logression_momentum=Logistics_momentum(images)\n",
        "        \n",
        "        loss_SVM = torch.sum(torch.clamp(1 - output.t()*labels, min=0))/batch_size\n",
        "        loss_SVM_momentum = torch.sum(torch.clamp(1 - output_momentum.t()*label_momentum, min=0))/batch_size\n",
        "        loss_logression=torch.sum(torch.log(1 + torch.exp(-(output_logression.t()*labels))))/batch_size\n",
        "        loss_log_momentum=torch.sum(torch.log(1 + torch.exp(-(output_logression_momentum.t()*labels))))/batch_size\n",
        "        \n",
        "        optimizer_SGD.zero_grad()\n",
        "        loss_SVM.backward()\n",
        "        optimizer_SGD.step()\n",
        "        \n",
        "        optimizer_Momentum.zero_grad()\n",
        "        loss_SVM_momentum.backward()\n",
        "        optimizer_Momentum.step()\n",
        "        \n",
        "        optimizer_logistics_reg.zero_grad()\n",
        "        loss_logression.backward()\n",
        "        optimizer_logistics_reg.step()\n",
        "        \n",
        "        optimizer_logistics_momentum.zero_grad()\n",
        "        loss_log_momentum.backward()\n",
        "        optimizer_logistics_momentum.step()\n",
        "        \n",
        "        total_batches=total_batches+1\n",
        "        total_loss = total_loss+loss_SVM.item()\n",
        "        total_loss_momentum=total_loss_momentum+loss_SVM_momentum.item()\n",
        "        total_loss_logression=total_loss_logression+loss_logression.item()\n",
        "        total_loss_logression_momentum=total_loss_logression_momentum+loss_log_momentum.item()\n",
        "    ## Print your results every epoch\n",
        "    print('Average loss SVM of epoch::{} is : [{}], SVM momentum: [{}]'\n",
        "          .format(epoch+1,total_loss/total_batches,total_loss_momen/total_batches))\n",
        "    print('Average loss Logistic Regression of epoch::{} is : [{}], Logistic Regression momentum: [{}]'\n",
        "          .format(epoch+1,total_loss_logression/total_batches,total_loss_logression_momentum/total_batches))\n",
        "\n",
        "\n",
        "# Test the Model\n",
        "correct = 0.\n",
        "correct_momentum=0.\n",
        "correct_log=0.\n",
        "correct_log_momentum=0.\n",
        "total = 0.\n",
        "for images, labels in test_loader:\n",
        "    images = images.view(-1, 28*28)\n",
        "    \n",
        "## Put your prediction code here, currently use a random prediction\n",
        "    outputs = SVM_model(images)\n",
        "    prediction = outputs.data>=0\n",
        "    \n",
        "    output_momentum=SVM_Momentum(images)\n",
        "    prediction_momentum=output_momentum.data>=0\n",
        "    \n",
        "    output_log=torch.sigmoid(Logistics_model(images))\n",
        "    prediction_log=output_log.data>=0.5\n",
        "    \n",
        "    output_logression_momentum=torch.sigmoid(Logistics_momentum(images))\n",
        "    prediction_log_momentum=output_logression_momentum.data>=0.5\n",
        "\n",
        "    correct += (prediction.view(-1).long() == labels).sum()\n",
        "    correct_momentum += (prediction_momentum.view(-1).long() == labels).sum()\n",
        "    correct_log += (prediction_log.view(-1).long() == labels).sum()\n",
        "    correct_log_momentum += (prediction_log_momentum.view(-1).long() == labels).sum()\n",
        "    total += images.shape[0]\n",
        "print('Accuracy of the model on the test images ------SVM: %f %%' % (100 * (correct.float() / total)))\n",
        "print('Accuracy of the model on the test images ------SVM/Momentum: %f %%' % (100 * (correct_momentum.float() / total)))\n",
        "print('Accuracy of the model on the test images ------Logistic RG: %f %%' % (100 * (correct_log.float() / total)))\n",
        "print('Accuracy of the model on the test images ------Logistic RG/Momentum: %f %%' % (100 * (correct_log_momentum.float() / total)))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average loss SVM of epoch::1 is : [0.005270114295523275], SVM momentum: [0.0016987147938572998]\n",
            "Average loss Logistic Regression of epoch::1 is : [0.01528551916808191], Logistic Regression momentum: [0.004845063480774335]\n",
            "Average loss SVM of epoch::2 is : [0.005234157337308532], SVM momentum: [0.0016987147938572998]\n",
            "Average loss Logistic Regression of epoch::2 is : [0.015174259034201804], Logistic Regression momentum: [0.004819011560293159]\n",
            "Average loss SVM of epoch::3 is : [0.005198388407477225], SVM momentum: [0.0016987147938572998]\n",
            "Average loss Logistic Regression of epoch::3 is : [0.015065179001822165], Logistic Regression momentum: [0.004791478332451949]\n",
            "Average loss SVM of epoch::4 is : [0.005162965407538594], SVM momentum: [0.0016987147938572998]\n",
            "Average loss Logistic Regression of epoch::4 is : [0.014958574471882346], Logistic Regression momentum: [0.004764854462906681]\n",
            "Average loss SVM of epoch::5 is : [0.005127342107395331], SVM momentum: [0.0016987147938572998]\n",
            "Average loss Logistic Regression of epoch::5 is : [0.014854083329232203], Logistic Regression momentum: [0.004739712415477073]\n",
            "Average loss SVM of epoch::6 is : [0.005092502148313956], SVM momentum: [0.0016987147938572998]\n",
            "Average loss Logistic Regression of epoch::6 is : [0.014751879815858874], Logistic Regression momentum: [0.004714057882077701]\n",
            "Average loss SVM of epoch::7 is : [0.00505837970742523], SVM momentum: [0.0016987147938572998]\n",
            "Average loss Logistic Regression of epoch::7 is : [0.014651500107250129], Logistic Regression momentum: [0.004689725880532272]\n",
            "Average loss SVM of epoch::8 is : [0.005025721672508452], SVM momentum: [0.0016987147938572998]\n",
            "Average loss Logistic Regression of epoch::8 is : [0.014553207290274177], Logistic Regression momentum: [0.0046654804943381065]\n",
            "Average loss SVM of epoch::9 is : [0.004994703188651439], SVM momentum: [0.0016987147938572998]\n",
            "Average loss Logistic Regression of epoch::9 is : [0.014456835749436809], Logistic Regression momentum: [0.004640944085420213]\n",
            "Average loss SVM of epoch::10 is : [0.004965280234399769], SVM momentum: [0.0016987147938572998]\n",
            "Average loss Logistic Regression of epoch::10 is : [0.01436242738014294], Logistic Regression momentum: [0.004618377775933377]\n",
            "Accuracy of the model on the test images ------SVM: 99.858162 %\n",
            "Accuracy of the model on the test images ------SVM/Momentum: 99.952721 %\n",
            "Accuracy of the model on the test images ------Logistic RG: 99.858162 %\n",
            "Accuracy of the model on the test images ------Logistic RG/Momentum: 99.905434 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}